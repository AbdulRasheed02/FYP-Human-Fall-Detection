{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook will allow you to train or run a model on an individual modality\n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from Models.Base_3DCAE import Base_3DCAE \n",
    "from io import StringIO\n",
    "import os\n",
    "import ffmpeg\n",
    "import pdb\n",
    "import parameters\n",
    "from functions import create_pytorch_dataset\n",
    "from functions import get_total_performance_metrics\n",
    "from functions import get_performance_metrics\n",
    "from functions import get_global_performance_metrics\n",
    "from functions import get_window_metrics\n",
    "from functions import get_frame_metrics\n",
    "from functions import animate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "\n",
    "window_len = parameters.window_len\n",
    "stride = parameters.stride\n",
    "fair_comparison = parameters.fair_comparison\n",
    "\n",
    "device = parameters.device\n",
    "\n",
    "dropout = parameters.dropout\n",
    "learning_rate = parameters.learning_rate\n",
    "num_epochs = parameters.num_epochs\n",
    "chunk_size = parameters.chunk_size\n",
    "forward_chunk = parameters.forward_chunk\n",
    "forward_chunk_size = parameters.forward_chunk_size\n",
    "loss_fn = parameters.loss_fn\n",
    "\n",
    "def full_pipeline(name, dset, window_len, fair_comparison, path, stride, modelpath):   \n",
    "\n",
    "    # Lets load the H%PY dataset into a pytorch dataset class.Please see dataset_creator on how to generate the H5PY file. \n",
    "    Test_Dataset, test_dataloader, Train_Dataset, train_dataloader = create_pytorch_dataset(name, dset, path, window_len, fair_comparison, stride, TOD = 'Both')\n",
    "    print('Train Dataloader - {}'.format(len(train_dataloader)))\n",
    "    print('Test Dataloader - {}'.format(len(test_dataloader)))\n",
    "    \n",
    "    # Now lets train our model\n",
    "\n",
    "    # prepare for GPU training \n",
    "    print('Device Used - ' + device)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # select which model to use\n",
    "    model = Base_3DCAE().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def train_model(filepath):\n",
    "        print(\"Training has Begun\")\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            val_loss = 0\n",
    "            frame_stats = [] \n",
    "            window_stats = [] \n",
    "            for i, (sample, labels) in enumerate(train_dataloader):\n",
    "                # ===================forward=====================\n",
    "                sample = sample.to(device, dtype=torch.float)\n",
    "                # split sample into smaller sizes due to GPU memory constraints\n",
    "                chunks = torch.split(sample, chunk_size, dim=1)\n",
    "                recon_vid = []\n",
    "\n",
    "                for chunk in chunks:\n",
    "                    output = model(chunk)\n",
    "                    output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                    model.zero_grad()\n",
    "                    loss = loss_fn(output, chunk)\n",
    "                    recon_vid.append(output)\n",
    "                    # ===================backward====================\n",
    "                    # Getting gradients w.r.t. parameters\n",
    "                    loss.backward()\n",
    "                    # Updating parameters\n",
    "                    optimizer.step()\n",
    "                    # Clear gradients w.r.t. parameters\n",
    "                    optimizer.zero_grad()\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                if epoch == num_epochs-1:\n",
    "                    output = torch.cat(recon_vid, dim=1)\n",
    "                    # convert tensors to numpy arrays for easy manipluations\n",
    "                    sample = sample.data.cpu().numpy()\n",
    "                    output = output.data.cpu().numpy()\n",
    "                    labels = labels.data.cpu().numpy()\n",
    "                    frame_std, frame_mean, frame_labels, window_std, window_mean, window_labels = get_performance_metrics(sample, output, labels, window_len)\n",
    "                    frame_stats.append([frame_mean, frame_std, frame_labels])\n",
    "                    window_stats.append([window_mean, window_std, window_labels])\n",
    "            \n",
    "            if epoch == num_epochs-1:\n",
    "                #get_total_performance_metrics(frame_stats, window_stats, window_len)\n",
    "                recon_errors = []\n",
    "                recon_labels = []\n",
    "                for i in range(len(frame_stats)):\n",
    "                    # print(i)\n",
    "                    # this a single video metrics\n",
    "                    frame_mean, frame_std, frame_labels = frame_stats[i]\n",
    "                    recon_errors.append([frame_mean, frame_std])\n",
    "                    recon_labels.append(frame_labels)    \n",
    "                np.save(project_directory+\"\\Output\\Recon_Errors\\\\train_recon_errors_{}.npy\".format(modality), recon_errors)\n",
    "                np.save(project_directory+\"\\Output\\Recon_Errors\\\\train_recon_labels_{}.npy\".format(modality), recon_labels)\n",
    "    \n",
    "            # ===================log========================\n",
    "            print(\"epoch [{}/{}], loss:{:.4f}\".format(epoch + 1, num_epochs, loss.item()))\n",
    "            torch.save(model.state_dict(), filepath) # save the model each epoch at location filepath\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Training has Completed\")\n",
    "        \n",
    "   \n",
    "    def foward_pass(path):\n",
    "        model.load_state_dict(torch.load(path)) # load a saved model \n",
    "        model.eval()\n",
    "\n",
    "        frame_stats = []\n",
    "        window_stats = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            print(\"foward pass occuring\")\n",
    "            # just forward pass of model on test dataset\n",
    "            for j, (sample, labels) in enumerate(test_dataloader):\n",
    "                # foward pass to get output\n",
    "                torch.cuda.empty_cache()\n",
    "                sample = sample.to(device, dtype=torch.float)\n",
    "                chunks = torch.split(sample, forward_chunk, dim=1)\n",
    "                recon_vid = []\n",
    "                for chunk in chunks:\n",
    "                    output = model(chunk)\n",
    "                    output = output.to(device).permute(1, 0, 2, 3, 4)\n",
    "                    recon_vid.append(output)\n",
    "                    torch.cuda.empty_cache()\n",
    "                output = torch.cat(recon_vid, dim=1)\n",
    "                # convert tensors to numpy arrays for easy manipluations\n",
    "                sample = sample.data.cpu().numpy()\n",
    "                output = output.data.cpu().numpy()\n",
    "                labels = labels.data.cpu().numpy()\n",
    "\n",
    "\n",
    "                frame_std, frame_mean, frame_labels, window_std, window_mean, window_labels = get_performance_metrics(sample, output, labels, window_len)\n",
    "                frame_stats.append([frame_mean, frame_std, frame_labels])\n",
    "                window_stats.append([window_mean, window_std, window_labels])\n",
    "                \n",
    "                #if j % 10 == 0:\n",
    "                    #print(sample.shape)\n",
    "                    #animate(sample[0, :, :, :, :], output[0, :, :, :, :], frame_mean, dset, start_time)\n",
    "                \n",
    "        return(frame_stats, window_stats)\n",
    "    \n",
    "    start_time = str(datetime.datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "    modality = (name + start_time)\n",
    "    filepath = (project_directory+\"\\Output\\Models\\\\\"+ modality + start_time)\n",
    "    # comment out this call if you dont want to train a model\n",
    "    train_model(filepath)\n",
    "\n",
    "    # INSERT modelpath instead of filepath to use a specified pre trained model \n",
    "    frame_stats, window_stats = foward_pass(filepath)\n",
    "    \n",
    "    print(modality)\n",
    "    get_total_performance_metrics(modality, frame_stats, window_stats, window_len)\n",
    "    get_global_performance_metrics(modality, frame_stats, window_stats, window_len)\n",
    "   \n",
    "    return() \n",
    "\n",
    "# Directory names of the raw dataset from the Fall-Data folder\n",
    "# list_of_files = ['Thermal','ONI_IR','IP'] \n",
    "list_of_files = ['Thermal']\n",
    "\n",
    "# Dataset names used during H5PY file creation (dsets variable from dataset_creator.py)\n",
    "# list_of_datasets = ['Thermal_T3','ONI_IR_T','IP_T']\n",
    "list_of_datasets = ['Thermal_T3'] \n",
    "\n",
    "# List of pre-trained model weight location if wanting to test trained model \n",
    "# list_of_models = ['x','x','x','x','x','x'] # after training - it will save them in the Models folder\n",
    "list_of_models = ['x'] # after training - it will save them in the Models folder\n",
    "\n",
    "script_directory=os.getcwd()\n",
    "project_directory=os.path.dirname(script_directory)\n",
    "\n",
    "for i in range(len(list_of_datasets)):\n",
    "    modelpath = list_of_models[i]\n",
    "    name = list_of_datasets[i]\n",
    "    dset = list_of_files[i]\n",
    "    path = \"{}\\Dataset\\H5PY\\Data_set-{}-imgdim64x64.h5\".format(project_directory,name) \n",
    "    full_pipeline(name, dset, window_len, fair_comparison, path, stride, modelpath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
